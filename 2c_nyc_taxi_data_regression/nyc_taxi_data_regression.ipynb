{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC taxi data regression\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](../../configuration.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Define different `CommandComponent` using YAML\n",
    "- Create `Pipeline` load these components from YAML\n",
    "\n",
    "**Motivations** - This notebook explains how to load component via SDK then use these components to build pipeline. We use NYC dataset, build pipeline with five steps, prep data, transform data, train model, predict results and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1 Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-identity\n",
      "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure-identity)\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Downloading cryptography-44.0.0-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity)\n",
      "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-identity) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from cryptography>=2.5->azure-identity) (1.17.0)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity)\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pycparser in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2024.8.30)\n",
      "Downloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
      "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "Downloading cryptography-44.0.0-cp37-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "Downloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: PyJWT, portalocker, cryptography, azure-core, msal, msal-extensions, azure-identity\n",
      "Successfully installed PyJWT-2.9.0 azure-core-1.32.0 azure-identity-1.19.0 cryptography-44.0.0 msal-1.31.1 msal-extensions-1.2.0 portalocker-2.10.1\n",
      "Collecting azure-ai-ml\n",
      "  Downloading azure_ai_ml-1.23.1-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (6.0.2)\n",
      "Collecting msrest>=0.6.18 (from azure-ai-ml)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (1.32.0)\n",
      "Collecting azure-mgmt-core>=1.3.0 (from azure-ai-ml)\n",
      "  Downloading azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting marshmallow>=3.5 (from azure-ai-ml)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (4.23.0)\n",
      "Requirement already satisfied: tqdm in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (4.67.1)\n",
      "Collecting strictyaml (from azure-ai-ml)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (2.9.0)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-ml)\n",
      "  Downloading azure_storage_blob-12.24.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting azure-storage-file-share (from azure-ai-ml)\n",
      "  Downloading azure_storage_file_share-12.20.0-py3-none-any.whl.metadata (49 kB)\n",
      "Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml)\n",
      "  Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pydash>=6.0.0 (from azure-ai-ml)\n",
      "  Downloading pydash-8.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting isodate (from azure-ai-ml)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-common>=1.1 (from azure-ai-ml)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-ai-ml) (4.12.2)\n",
      "Collecting opencensus-ext-azure (from azure-ai-ml)\n",
      "  Downloading opencensus_ext_azure-1.1.14-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting opencensus-ext-logging (from azure-ai-ml)\n",
      "  Downloading opencensus_ext_logging-0.1.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (44.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.3.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (6.4.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.20.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.18->azure-ai-ml)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from opencensus-ext-azure->azure-ai-ml) (1.19.0)\n",
      "Collecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from opencensus-ext-azure->azure-ai-ml) (6.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=4.0.0->azure-ai-ml) (3.21.0)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pycparser in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /home/geor/anaconda3/envs/proteusAI/lib/python3.8/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (2.10.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading azure_ai_ml-1.23.1-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
      "Downloading azure_storage_blob-12.24.0-py3-none-any.whl (408 kB)\n",
      "Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl (258 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Downloading pydash-8.0.4-py3-none-any.whl (101 kB)\n",
      "Downloading azure_storage_file_share-12.20.0-py3-none-any.whl (286 kB)\n",
      "Downloading opencensus_ext_azure-1.1.14-py2.py3-none-any.whl (43 kB)\n",
      "Downloading opencensus_ext_logging-0.1.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: opencensus-context, azure-common, pydash, pyasn1, protobuf, oauthlib, marshmallow, isodate, cachetools, strictyaml, rsa, requests-oauthlib, pyasn1-modules, proto-plus, googleapis-common-protos, msrest, google-auth, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, google-api-core, azure-storage-file-datalake, opencensus, opencensus-ext-logging, opencensus-ext-azure, azure-ai-ml\n",
      "Successfully installed azure-ai-ml-1.23.1 azure-common-1.1.28 azure-mgmt-core-1.5.0 azure-storage-blob-12.24.0 azure-storage-file-datalake-12.18.0 azure-storage-file-share-12.20.0 cachetools-5.5.0 google-api-core-2.24.0 google-auth-2.37.0 googleapis-common-protos-1.66.0 isodate-0.7.2 marshmallow-3.22.0 msrest-0.7.1 oauthlib-3.2.2 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.14 opencensus-ext-logging-0.1.1 proto-plus-1.25.0 protobuf-5.29.2 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydash-8.0.4 requests-oauthlib-2.0.0 rsa-4.9 strictyaml-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-identity \n",
    "!pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get a handle to the workspace\n",
    "\n",
    "We use config file to connect to a workspace. The Azure ML workspace should be configured with computer cluster. [Check this notebook for configure a workspace](../../configuration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter details of your AML workspace\n",
    "subscription_id = \"096b3461-7e4d-4cc6-a17c-6f3d723c6277\"\n",
    "resource_group = \"testrgajuaza01\"\n",
    "workspace = \"Testworkspace\"\n",
    "\n",
    "# Get a handle to workspace\n",
    "#ml_client = MLClient.from_config(credential=credential)\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "# # Retrieve an already attached Azure Machine Learning Compute.\n",
    "# cluster_name = \"Redi\"\n",
    "# print(ml_client.compute.get(cluster_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "name": "build-pipeline-with-pipeline-output",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_dir = \"\"\n",
    "\n",
    "# 1. Load components\n",
    "prepare_data = load_component(source=parent_dir + \"./prep.yml\")\n",
    "transform_data = load_component(source=parent_dir + \"./transform.yml\")\n",
    "train_model = load_component(source=parent_dir + \"./train.yml\")\n",
    "predict_result = load_component(source=parent_dir + \"./predict.yml\")\n",
    "score_data = load_component(source=parent_dir + \"./score.yml\")\n",
    "\n",
    "# 2. Construct pipeline\n",
    "@pipeline()\n",
    "def nyc_taxi_data_regression(pipeline_job_input):\n",
    "    \"\"\"NYC taxi data regression example.\"\"\"\n",
    "    prepare_sample_data = prepare_data(raw_data=pipeline_job_input)\n",
    "    transform_sample_data = transform_data(\n",
    "        clean_data=prepare_sample_data.outputs.prep_data\n",
    "    )\n",
    "    train_with_sample_data = train_model(\n",
    "        training_data=transform_sample_data.outputs.transformed_data\n",
    "    )\n",
    "    predict_with_sample_data = predict_result(\n",
    "        model_input=train_with_sample_data.outputs.model_output,\n",
    "        test_data=train_with_sample_data.outputs.test_data,\n",
    "    )\n",
    "    score_with_sample_data = score_data(\n",
    "        predictions=predict_with_sample_data.outputs.predictions,\n",
    "        model=train_with_sample_data.outputs.model_output,\n",
    "    )\n",
    "    return {\n",
    "        \"pipeline_job_prepped_data\": prepare_sample_data.outputs.prep_data,\n",
    "        \"pipeline_job_transformed_data\": transform_sample_data.outputs.transformed_data,\n",
    "        \"pipeline_job_trained_model\": train_with_sample_data.outputs.model_output,\n",
    "        \"pipeline_job_test_data\": train_with_sample_data.outputs.test_data,\n",
    "        \"pipeline_job_predictions\": predict_with_sample_data.outputs.predictions,\n",
    "        \"pipeline_job_score_report\": score_with_sample_data.outputs.score_report,\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline_job = nyc_taxi_data_regression(\n",
    "    Input(type=\"uri_folder\", path=parent_dir + \"./data/\")\n",
    ")\n",
    "# demo how to change pipeline output settings\n",
    "pipeline_job.outputs.pipeline_job_prepped_data.mode = \"rw_mount\"\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"Redi\"\n",
    "# set pipeline level datastore\n",
    "pipeline_job.settings.default_datastore = \"workspaceblobstore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(AuthorizationFailed) The client 'georet@dtu.dk' with object id '75ae6087-e4ff-4199-a47d-0ad68ddb47fd' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/codes/versions/write' over scope '/subscriptions/096b3461-7e4d-4cc6-a17c-6f3d723c6277/resourceGroups/testrgajuaza01/providers/Microsoft.MachineLearningServices/workspaces/Testworkspace/codes/353f49a1-5c7b-4966-a3af-760f4d072c0d/versions/1' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 'georet@dtu.dk' with object id '75ae6087-e4ff-4199-a47d-0ad68ddb47fd' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/codes/versions/write' over scope '/subscriptions/096b3461-7e4d-4cc6-a17c-6f3d723c6277/resourceGroups/testrgajuaza01/providers/Microsoft.MachineLearningServices/workspaces/Testworkspace/codes/353f49a1-5c7b-4966-a3af-760f4d072c0d/versions/1' or the scope is invalid. If access was recently granted, please refresh your credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# submit job to workspace\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pipeline_job\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_telemetry/activity.py:372\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 372\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    375\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:689\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(job, raise_on_failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_upload_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationException, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=W0718\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     log_and_raise_error(ex)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:1137\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: Job) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m    :rtype: Job\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_azureml_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orchestrators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_asset_arm_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;66;03m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_job_inputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_group_inputs(job\u001b[38;5;241m.\u001b[39minputs), job\u001b[38;5;241m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:1428\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_arm_id_for_automl_job(job, resolver, inside_pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, PipelineJob):\n\u001b[0;32m-> 1428\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_for_pipeline_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, FineTuningJob):\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:1617\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_pipeline_job\u001b[0;34m(self, pipeline_job, resolver)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;66;03m# Process each component job\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1617\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_dependencies_for_pipeline_component_jobs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComponentException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m   1622\u001b[0m         message\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m   1623\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m   1624\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mno_personal_data_message,\n\u001b[1;32m   1625\u001b[0m         error_category\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39merror_category,\n\u001b[1;32m   1626\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:1135\u001b[0m, in \u001b[0;36mComponentOperations._resolve_dependencies_for_pipeline_component_jobs\u001b[0;34m(self, component, resolver)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon supported job type in Pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(job_instance)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ComponentException(\n\u001b[1;32m   1129\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1130\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCOMPONENT,\n\u001b[1;32m   1131\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1132\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m   1133\u001b[0m         )\n\u001b[0;32m-> 1135\u001b[0m \u001b[43mcomponent_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_utils/_cache_utils.py:434\u001b[0m, in \u001b[0;36mCachedNodeResolver.resolve_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# release lock even if exception happens\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_utils/_cache_utils.py:394\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_on_disk_cache_enabled() \u001b[38;5;129;01mand\u001b[39;00m is_private_preview_enabled():\n\u001b[1;32m    392\u001b[0m     cache_contents_to_resolve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_cache_contents_from_disk(cache_contents_to_resolve)\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_cache_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_contents_to_resolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_back_component_to_nodes(dict_of_nodes_to_resolve)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_utils/_cache_utils.py:310\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_cache_contents\u001b[0;34m(self, cache_contents_to_resolve, resolver)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(_map_func, cache_contents_to_resolve))\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_map_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_contents_to_resolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_utils/_cache_utils.py:296\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_cache_contents.<locals>._map_func\u001b[0;34m(_cache_content)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_map_func\u001b[39m(_cache_content: _CacheContent):\n\u001b[0;32m--> 296\u001b[0m     _cache_content\u001b[38;5;241m.\u001b[39marm_id \u001b[38;5;241m=\u001b[39m \u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cache_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mazureml_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAzureMLResourceType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPONENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_on_disk_cache_enabled() \u001b[38;5;129;01mand\u001b[39;00m is_private_preview_enabled():\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_to_on_disk_cache(_cache_content\u001b[38;5;241m.\u001b[39mon_disk_hash, _cache_content\u001b[38;5;241m.\u001b[39marm_id)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:246\u001b[0m, in \u001b[0;36mOperationOrchestrator.get_asset_arm_id\u001b[0;34m(self, asset, azureml_type, register_asset, sub_workspace_resource)\u001b[0m\n\u001b[1;32m    244\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_arm_id(asset, register_asset\u001b[38;5;241m=\u001b[39mregister_asset)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m azureml_type \u001b[38;5;241m==\u001b[39m AzureMLResourceType\u001b[38;5;241m.\u001b[39mCOMPONENT \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asset, Component):\n\u001b[0;32m--> 246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_component_arm_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported azureml type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for asset: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:390\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_component_arm_id\u001b[0;34m(self, component)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# If component arm id is already resolved, return the id otherwise get arm id via remote call.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Register the component if necessary, and FILL BACK the arm id to component to reduce remote call.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m component\u001b[38;5;241m.\u001b[39mid:\n\u001b[0;32m--> 390\u001b[0m     component\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_anonymous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(component\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_telemetry/activity.py:372\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 372\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    375\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:619\u001b[0m, in \u001b[0;36mComponentOperations.create_or_update\u001b[0;34m(self, component, version, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Only upload dependencies if component is NOT IPP\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m component\u001b[38;5;241m.\u001b[39m_intellectual_property:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_upload_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m name, version \u001b[38;5;241m=\u001b[39m component\u001b[38;5;241m.\u001b[39m_get_rest_name_version()\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m component\u001b[38;5;241m.\u001b[39m_is_anonymous \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_if_no_change\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:795\u001b[0m, in \u001b[0;36mComponentOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, component)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[38;5;28mself\u001b[39m, component: Component) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     resolver \u001b[38;5;241m=\u001b[39m OperationOrchestrator(\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_operations, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_scope, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_config\n\u001b[1;32m    793\u001b[0m     )\u001b[38;5;241m.\u001b[39mget_asset_arm_id\n\u001b[0;32m--> 795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_dependencies_for_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:821\u001b[0m, in \u001b[0;36mComponentOperations._resolve_dependencies_for_component\u001b[0;34m(self, component, resolver, jobs_only)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    814\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    815\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCOMPONENT,\n\u001b[1;32m    816\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    817\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    818\u001b[0m     )\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# resolve component's code\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m \u001b[43m_try_resolve_code_for_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# resolve component's environment\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_resolve_environment_for_component(\n\u001b[1;32m    824\u001b[0m     component\u001b[38;5;241m=\u001b[39mcomponent,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    825\u001b[0m     resolver\u001b[38;5;241m=\u001b[39mresolver,\n\u001b[1;32m    826\u001b[0m     _\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    827\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:1226\u001b[0m, in \u001b[0;36m_try_resolve_code_for_component\u001b[0;34m(component, resolver)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1226\u001b[0m component\u001b[38;5;241m.\u001b[39m_fill_back_code_value(\u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mazureml_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAzureMLResourceType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCODE\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:238\u001b[0m, in \u001b[0;36mOperationOrchestrator.get_asset_arm_id\u001b[0;34m(self, asset, azureml_type, register_asset, sub_workspace_resource)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# TODO: once the asset redesign is finished, this logic can be replaced with unified API\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m azureml_type \u001b[38;5;241m==\u001b[39m AzureMLResourceType\u001b[38;5;241m.\u001b[39mCODE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asset, Code):\n\u001b[0;32m--> 238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_code_asset_arm_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregister_asset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregister_asset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m azureml_type \u001b[38;5;241m==\u001b[39m AzureMLResourceType\u001b[38;5;241m.\u001b[39mENVIRONMENT \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asset, Environment):\n\u001b[1;32m    240\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_environment_arm_id(asset, register_asset\u001b[38;5;241m=\u001b[39mregister_asset)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:304\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_code_asset_arm_id\u001b[0;34m(self, code_asset, register_asset)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uploaded_code_asset\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (MlException, HttpResponseError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AssetException(\n\u001b[1;32m    307\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError with code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mASSET,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    312\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:279\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_code_asset_arm_id\u001b[0;34m(self, code_asset, register_asset)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_datastore_name(code_asset\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m register_asset:\n\u001b[0;32m--> 279\u001b[0m     code_asset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_code_assets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_asset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(code_asset\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m    281\u001b[0m sas_info \u001b[38;5;241m=\u001b[39m get_storage_info_for_non_registry_asset(\n\u001b[1;32m    282\u001b[0m     service_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_assets\u001b[38;5;241m.\u001b[39m_service_client,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     workspace_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_scope\u001b[38;5;241m.\u001b[39mworkspace_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     resource_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_scope\u001b[38;5;241m.\u001b[39mresource_group_name,\n\u001b[1;32m    287\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_code_operations.py:212\u001b[0m, in \u001b[0;36mCodeOperations.create_or_update\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ex) \u001b[38;5;241m==\u001b[39m ASSET_PATH_ERROR:\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AssetPathException(\n\u001b[1;32m    207\u001b[0m             message\u001b[38;5;241m=\u001b[39mCHANGED_ASSET_PATH_MSG,\n\u001b[1;32m    208\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCODE,\n\u001b[1;32m    209\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mCHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,\n\u001b[1;32m    210\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    211\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/operations/_code_operations.py:150\u001b[0m, in \u001b[0;36mCodeOperations.create_or_update\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    148\u001b[0m     name, version \u001b[38;5;241m=\u001b[39m _get_existing_asset_name_and_version(existing_asset)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(name\u001b[38;5;241m=\u001b[39mname, version\u001b[38;5;241m=\u001b[39mversion)\n\u001b[0;32m--> 150\u001b[0m sas_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_storage_info_for_non_registry_asset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m sas_uri \u001b[38;5;241m=\u001b[39m sas_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msas_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    158\u001b[0m blob_uri \u001b[38;5;241m=\u001b[39m sas_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblob_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_utils/_asset_utils.py:1147\u001b[0m, in \u001b[0;36mget_storage_info_for_non_registry_asset\u001b[0;34m(service_client, workspace_name, name, version, resource_group)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get SAS uri and blob uri for non-registry asset. Note that this function won't return the same\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03mSAS uri and blob uri for the same asset. It will return a new SAS uri and blob uri every time it is called.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;124;03m:param service_client: Service client\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m:rtype: Dict[str, str]\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m request_body \u001b[38;5;241m=\u001b[39m PendingUploadRequestDto(pending_upload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemporaryBlobReference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1147\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mservice_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_versions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_get_start_pending_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m sas_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msas_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mblob_reference_for_consumption\u001b[38;5;241m.\u001b[39mcredential\u001b[38;5;241m.\u001b[39msas_uri,\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblob_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mblob_reference_for_consumption\u001b[38;5;241m.\u001b[39mblob_uri,\n\u001b[1;32m   1158\u001b[0m }\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sas_info\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteusAI/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py:680\u001b[0m, in \u001b[0;36mCodeVersionsOperations.create_or_get_start_pending_upload\u001b[0;34m(self, resource_group_name, workspace_name, name, version, body, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    679\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    682\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPendingUploadResponseDto\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline_response)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (AuthorizationFailed) The client 'georet@dtu.dk' with object id '75ae6087-e4ff-4199-a47d-0ad68ddb47fd' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/codes/versions/write' over scope '/subscriptions/096b3461-7e4d-4cc6-a17c-6f3d723c6277/resourceGroups/testrgajuaza01/providers/Microsoft.MachineLearningServices/workspaces/Testworkspace/codes/353f49a1-5c7b-4966-a3af-760f4d072c0d/versions/1' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 'georet@dtu.dk' with object id '75ae6087-e4ff-4199-a47d-0ad68ddb47fd' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/codes/versions/write' over scope '/subscriptions/096b3461-7e4d-4cc6-a17c-6f3d723c6277/resourceGroups/testrgajuaza01/providers/Microsoft.MachineLearningServices/workspaces/Testworkspace/codes/353f49a1-5c7b-4966-a3af-760f4d072c0d/versions/1' or the scope is invalid. If access was recently granted, please refresh your credentials."
     ]
    }
   ],
   "source": [
    "# submit job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline_samples\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of running a pipeline job [here](../)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Build pipeline with components for 5 jobs - prep data, transform data, train model, predict results and evaluate model performance"
  },
  "kernelspec": {
   "display_name": "proteusAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
